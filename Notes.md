# Introduction

In this blog post I want to give a brief introduction to Reinforcement learning, overview of concepts involved. I cannot obviously cover everything in detail, instead I want to talk about how I learned about it and talk about the resources I found useful to get into it and solve complex environments. I will also discuss briefly various popular RL algorithms.

I played with one simple environment called `MountainCar` and one complex environment called `Humanoid` to test various RL algorithms.

## MountainCar

<div style='position:relative;padding-bottom:54%'><iframe src='https://gfycat.com/ifr/WideeyedUntriedJellyfish' frameborder='0' scrolling='no' width='100%' height='100%' style='position:absolute;top:0;left:0' allowfullscreen></iframe></div>

## Humanoid

<div style='position:relative; padding-bottom:66.67%'><iframe src='https://gfycat.com/ifr/WaryUnhappyEuropeanfiresalamander' frameborder='0' scrolling='no' width='100%' height='100%' style='position:absolute;top:0;left:0;' allowfullscreen></iframe></div>

I will also 


# Reinfrocement Learning

# Keywords
* Agent
* Environment
* Observations, State
* Actions
* Reward
* Value function
* Policy function
* Q value
* Markov Decision Process (MDP)

# Value of WANDB

# How I learnt RL

# Actor Critic

# Description of the environment

# Actor Critic

# Hyperparameters

# DDPG

# TRPO

# PPO1

# PPO2

# Q+

# Results

```
wandb:     loss_pol_surr ▁█
wandb:         EpLenMean █▁
wandb:   ev_tdlam_before ▁█
wandb: Waiting for final file modifications.
wandb: Syncing files in wandb/run-20180704_085400-ey2kgq4t:
wandb:   wandb-debug.log
wandb:   config.yaml
wandb:   humanoid_policy.data-00000-of-00001.tempstate14432056802831918837
wandb:   humanoid_policy.index.tempstate5254927434801209082
wandb:   checkpoint.tmp9bc4dd33814742488021e2bbbaab8f00
wandb:   humanoid_policy.meta.tmpb3a5730ced754aadb9f46098d3cdde1d
wandb:   humanoid.mp4
wandb:   humanoid.meta.json
wandb:   wandb-metadata.json
wandb:
wandb: Verifying uploaded files... verified!
```